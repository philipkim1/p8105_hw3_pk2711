Homework 3
================
Philip Kim
10/12/2021

-   [Problem 1](#problem-1)
    -   [Dataset description](#dataset-description)
    -   [Number of Aisles/Most Ordered from
        Aisles](#number-of-aislesmost-ordered-from-aisles)
    -   [Aisle Plot](#aisle-plot)
    -   [Most Popular Item Table](#most-popular-item-table)
    -   [Pink Lady Apples/Coffee Ice Cream
        Table](#pink-lady-applescoffee-ice-cream-table)
-   [Problem 2](#problem-2)
    -   [Data Cleaning](#data-cleaning)
    -   [States observed at 7 or more
        locations](#states-observed-at-7-or-more-locations)
    -   [Spaghetti Plot](#spaghetti-plot)
    -   [Two-Panel Plot](#two-panel-plot)
-   [Problem 3](#problem-3)
    -   [Load and Tidy Data](#load-and-tidy-data)
    -   [Total Activity per Day](#total-activity-per-day)
    -   [24-hour activity time course
        plot](#24-hour-activity-time-course-plot)

``` r
library(tidyverse)
library(knitr)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

# Problem 1

``` r
data("instacart")
```

## Dataset description

The instacart dataset contains 1384617 rows and 15 columns. This dataset
provides information on orders through Instacart via identifiers such as
`order_id`, `product_id`, `aisle_id` and etc. Accordingly, it gives in
formation on the time of the order such as the day of the week the order
was placed, `order_dow`, and the hour of the day, `order_hour_of_day`.
Through this data, we can see that most users tend to buy products that
they had purchased in the past, which was represented by a 1 in the
dataset. Correspondingly, the largest number of products ordered by a
single user was 80.

## Number of Aisles/Most Ordered from Aisles

``` r
aisle_df = 
  instacart %>% 
  group_by(aisle) %>% 
  summarize(n_obs = n()) %>% 
  arrange(desc(n_obs))
```

There are 134 aisles and the aisles with the most items ordered from are
the fresh vegetables and the fresh fruits aisles with 150,609 and
150,473 orders, respectively. These two aisles have almost double the
amount of orders from the next leading aisle, which is quite a big
margin.

## Aisle Plot

``` r
aisle_df %>% 
  filter(n_obs > 10000) %>% 
  mutate(
    aisle = as.factor(aisle),
    aisle = fct_reorder(aisle, (n_obs))) %>% 
  ggplot((aes(x = aisle, y = n_obs))) + 
  labs(
    title = "Item Popularity in Instacart",
    x = "Aisle Name",
    y = "Number of Ordered Items") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_col() +
  coord_flip()
```

<img src="p8105_hw3_pk2711_files/figure-gfm/unnamed-chunk-4-1.png" width="90%" />

As the graph shows, the fresh vegetables and fresh fruits are the most
popular items by a large margin which is then followed by packaged
vegetable fruits and yogurt. Towards the bottom of the list of items,
with more than 10,000 orders, include butter, oils vinegars, and dry
pasta. However, the differences arenâ€™t quite as large as we see between
the items at the top of the list.

## Most Popular Item Table

``` r
instacart %>% 
  filter(
    aisle == "baking ingredients" | 
    aisle == "dog food care" | 
    aisle == "packaged vegetables fruits") %>% 
  group_by(aisle, product_name) %>% 
  summarize(n_obs = n()) %>% 
  mutate(rank = rank(-n_obs)) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  relocate(-n_obs) %>% 
  kable(caption = "Most popular items in Baking Ingredients, Dog Food Care, and Packaged Vegetables Fruits")
```

| aisle                      | product_name                                  | rank | n_obs |
|:---------------------------|:----------------------------------------------|-----:|------:|
| baking ingredients         | Light Brown Sugar                             |    1 |   499 |
| baking ingredients         | Pure Baking Soda                              |    2 |   387 |
| baking ingredients         | Cane Sugar                                    |    3 |   336 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |    1 |    30 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |    2 |    28 |
| dog food care              | Small Dog Biscuits                            |    3 |    26 |
| packaged vegetables fruits | Organic Baby Spinach                          |    1 |  9784 |
| packaged vegetables fruits | Organic Raspberries                           |    2 |  5546 |
| packaged vegetables fruits | Organic Blueberries                           |    3 |  4966 |

Most popular items in Baking Ingredients, Dog Food Care, and Packaged
Vegetables Fruits

Organic Baby Spinach was the most popular packaged vegetable item,
whereas Light Brown Sugar was the most popular item in baking
ingredients. Accordingly, Snack Sticks Chicken & Rice Recipe Dog Treats
was the most popular item in dog food care. Although these were the
three most popular items in each aforementioned category, the number of
orders in the most popular packaged vegetables fruits items markedly
prevailed over the number of items in both baking ingredients and dog
food care.

## Pink Lady Apples/Coffee Ice Cream Table

``` r
instacart %>% 
  filter(product_name == "Pink Lady Apples" |
         product_name == "Coffee Ice Cream") %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  mutate(
    mean_hour = round(mean_hour, digits = 2),
    order_dow = recode(order_dow, "0" = "Sun",
                                  "1" = "Mon",
                                  "2" = "Tues",
                                  "3" = "Wed",
                                  "4" = "Thurs",
                                  "5" = "Fri",
                                  "6" = "Sat"),
    order_dow = as.factor(order_dow)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour) %>% 
  kable(caption = "Mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week")
```

| product_name     |   Sun |   Mon |  Tues |   Wed | Thurs |   Fri |   Sat |
|:-----------------|------:|------:|------:|------:|------:|------:|------:|
| Coffee Ice Cream | 13.77 | 14.32 | 15.38 | 15.32 | 15.22 | 12.26 | 13.83 |
| Pink Lady Apples | 13.44 | 11.36 | 11.70 | 14.25 | 11.55 | 12.78 | 11.94 |

Mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are
ordered on each day of the week

For the Coffee Ice Cream, the mean hour of day in which it is ordered is
earlier in the weekends when compared to the weekdays. For the Pink Lady
Apples, the mean hour of day that it is ordered is the latest on
Wednesday. When comparing the two items, the Coffee Ice Cream is
typically ordered later than the Pink Lady Apples.

# Problem 2

``` r
data("brfss_smart2010")
```

## Data Cleaning

``` r
brfss_tidy_smart2010 =
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health",
         response == "Excellent" |
         response == "Very good" |
         response == "Good" |
         response == "Fair" |   
         response == "Poor") %>% 
  mutate(response = as.factor(response),
         response = ordered(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent")))
```

## States observed at 7 or more locations

``` r
brfss_tidy_smart2010 %>% 
  filter(year == 2002 |
         year == 2010) %>%
  group_by(year, locationabbr) %>% 
  summarize(n_obs = n_distinct(locationdesc)) %>% 
  filter(n_obs >= 7) %>% 
  arrange(year, (n_obs)) %>% 
  kable()
```

| year | locationabbr | n_obs |
|-----:|:-------------|------:|
| 2002 | CT           |     7 |
| 2002 | FL           |     7 |
| 2002 | NC           |     7 |
| 2002 | MA           |     8 |
| 2002 | NJ           |     8 |
| 2002 | PA           |    10 |
| 2010 | CO           |     7 |
| 2010 | PA           |     7 |
| 2010 | SC           |     7 |
| 2010 | OH           |     8 |
| 2010 | MA           |     9 |
| 2010 | NY           |     9 |
| 2010 | NE           |    10 |
| 2010 | WA           |    10 |
| 2010 | CA           |    12 |
| 2010 | MD           |    12 |
| 2010 | NC           |    12 |
| 2010 | TX           |    16 |
| 2010 | NJ           |    19 |
| 2010 | FL           |    41 |

There were a total of 6 states that were observed at 7 or more locations
in 2002 which include CT, FL, MA, NC, NJ, and PA. Relatively, there were
a total of 14 states that were observed at 7 or more locations in 2010
which include CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, and
WA. A total of 5 states were observed at 7 or more locations in both
2002 and 2010, which include FL, MA, NC, NJ, and PA.

## Spaghetti Plot

``` r
brfss_tidy_smart2010 %>% 
  filter(response == "Excellent") %>% 
  group_by(year, locationabbr) %>% 
  summarize(mean_data_value = mean(data_value, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = mean_data_value)) +
  labs(
    x = "Year",
    y = "Average Data Value within State",
    title = "Average Data Value of those with \nExcellent Overall Health over Time by State") +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_line(aes(group = locationabbr))
```

<img src="p8105_hw3_pk2711_files/figure-gfm/unnamed-chunk-10-1.png" width="90%" />

The lowest average data value is 11.5 and is from WV in 2005.
Accordingly, four out of the five lowest average data values are from
WV. To contrast, the highest average data value is from UT in 2002.
There are no clear trends from this plot but it seems that the average
data value from all states, 2002 to 2010, hover around the 20 to 25
mark.

## Two-Panel Plot

``` r
brfss_tidy_smart2010 %>% 
  filter(year == 2006 |
         year == 2010,
         locationabbr == "NY") %>% 
  group_by(year, response) %>% 
  summarize(data_value = data_value) %>% 
  ggplot(aes(x = response, y = data_value)) +
  labs(
    x = "Response",
    y = "Data Value",
    title = "Distribution of Data Value by Response Type in 2006 and 2010") +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_boxplot() +
  facet_grid(. ~ year)
```

<img src="p8105_hw3_pk2711_files/figure-gfm/unnamed-chunk-11-1.png" width="90%" />

The distribution of data value seems to be quite similar for both the
years 2006 and 2010. The highest data values correspond to the responses
`Good` and `Very good` whereas the lowest data values correlate to
`Poor` for both 2006 and 2010.

# Problem 3

## Load and Tidy Data

``` r
accel_df = read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute_of_day",
    names_prefix = "activity_",
    values_to = "activity_count") %>% 
  mutate(
    weekend = if_else(day == "Saturday" | day == "Sunday", "weekend", "weekday"),
    minute_of_day = as.numeric(minute_of_day),
    day = as.factor(day),
    day = ordered(day, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))) %>% 
  relocate(week, day_id, weekend, everything())
```

There are 50400 rows and 6 columns within this dataset. There is a
specific `day_id` variable that differentiates the day from others and
`minute_of_day` variable that lists the exact minute of the day.
Accordingly, there is a `weekend` variable that states whether the given
day is a weekday or weekend and an `activity_count` that measures the
level of activity for any given minute. Throughout the five weeks, the
lowest activity count measured was a value of 1 whereas the highest
activity count recorded had a value of 8982, which was on Wednesday of
the second week.

## Total Activity per Day

``` r
accel_df %>% 
  group_by(week, day) %>% 
  summarize(total_activity_count = sum(activity_count)) %>% 
  kable()
```

| week | day       | total_activity_count |
|-----:|:----------|---------------------:|
|    1 | Sunday    |            631105.00 |
|    1 | Monday    |             78828.07 |
|    1 | Tuesday   |            307094.24 |
|    1 | Wednesday |            340115.01 |
|    1 | Thursday  |            355923.64 |
|    1 | Friday    |            480542.62 |
|    1 | Saturday  |            376254.00 |
|    2 | Sunday    |            422018.00 |
|    2 | Monday    |            295431.00 |
|    2 | Tuesday   |            423245.00 |
|    2 | Wednesday |            440962.00 |
|    2 | Thursday  |            474048.00 |
|    2 | Friday    |            568839.00 |
|    2 | Saturday  |            607175.00 |
|    3 | Sunday    |            467052.00 |
|    3 | Monday    |            685910.00 |
|    3 | Tuesday   |            381507.00 |
|    3 | Wednesday |            468869.00 |
|    3 | Thursday  |            371230.00 |
|    3 | Friday    |            467420.00 |
|    3 | Saturday  |            382928.00 |
|    4 | Sunday    |            260617.00 |
|    4 | Monday    |            409450.00 |
|    4 | Tuesday   |            319568.00 |
|    4 | Wednesday |            434460.00 |
|    4 | Thursday  |            340291.00 |
|    4 | Friday    |            154049.00 |
|    4 | Saturday  |              1440.00 |
|    5 | Sunday    |            138421.00 |
|    5 | Monday    |            389080.00 |
|    5 | Tuesday   |            367824.00 |
|    5 | Wednesday |            445366.00 |
|    5 | Thursday  |            549658.00 |
|    5 | Friday    |            620860.00 |
|    5 | Saturday  |              1440.00 |

It seems that as it got closer to the later weeks, the activity count on
the weekends started to decrease. Also, the days in the middle of the
week seem to be the most consistent in terms of activity count (e.g.,
Tuesday, Wednesday, Thursday) whereas the other days seem to comparably
dynamic.

## 24-hour activity time course plot

``` r
accel_df %>% 
  mutate(
    hour = minute_of_day %/% 60) %>% 
  group_by(day_id, day, hour) %>% 
  summarize(activity_count = sum(activity_count)) %>%
  ggplot(aes(x = hour, y = activity_count, color = day)) +
  labs(
    x = "Hour of the Day",
    y = "Activity Count",
    title = "24 Hour Activity Time Course per Day",
    color = "Day of the Week") +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_line(aes(group = day_id))
```

<img src="p8105_hw3_pk2711_files/figure-gfm/unnamed-chunk-14-1.png" width="90%" />

From this graph, the highest activity counts seem to be most prominent
at the 20th hour of the day, followed by spikes around the 10 hour mark.
Most of the activity seems to start around the 5 hour mark and end
towards the 23 hour mark. Accordingly, the hours that have the lowest
activity were those around the 24 and 0 hour marks. The participant
typically has the highest activity counts for the days of Monday and
Friday. This may be due to the weekday starting/ending.
